use std::{fs::File, io::Read};

use crate::token::{FnData, Token};

#[derive(Debug, thiserror::Error)]
pub enum SyntaxError {
    #[error("Invalid function definition")]
    FunctionDefinition,
}

#[derive(Debug, thiserror::Error)]
pub enum ErrorLexer {
    #[error("{0} not found")]
    FileNotFound(String),

    #[error("Generic syntax error")]
    GenericSyntaxError,

    #[error("Syntax Error: {0}")]
    SyntaxError(SyntaxError),

    #[error("EOF")]
    EOF,
}

#[derive(Debug)]
pub enum Started {
    Equal,
    Exclamation,
    LessThan,
    GreaterThan,
    DoubleQuote(String),
    Variable(String),
}

impl Started {
    pub fn to_token(self) -> Option<Token> {
        if let Started::DoubleQuote(_) = self {
            return None;
        }

        Some(match self {
            Started::Equal => Token::Assign,
            Started::Exclamation => Token::Inverse,
            Started::LessThan => Token::Less,
            Started::GreaterThan => Token::Greater,
            _ => unreachable!(),
        })
    }
}

#[derive(Debug)]
pub struct Lexer {
    file: Vec<char>,
    next: usize,
    tokens: Vec<Token>,
    started: Option<Started>,
}

impl Lexer {
    pub fn from_chars(chars: Vec<char>) -> Lexer {
        Lexer {
            file: chars,
            next: 0,
            tokens: Vec::new(),
            started: None,
        }
    }

    pub fn from_file(path: &str) -> Result<Lexer, ErrorLexer> {
        let mut buf = String::new();

        let Ok(mut file) = File::open(path) else {
            return Err(ErrorLexer::FileNotFound(path.to_string()));
        };

        file.read_to_string(&mut buf).unwrap();

        Ok(Lexer {
            file: buf.into_bytes().iter().map(|&u| u as char).collect(),
            next: 0,
            tokens: Vec::new(),
            started: None,
        })
    }

    pub fn lex(&mut self) -> Result<Vec<Token>, ErrorLexer> {
        loop {
            let tok = self.next_token();
            if let Err(ErrorLexer::EOF) = &tok {
                break;
            }

            if let Some(t) = tok? {
                self.tokens.push(t);
            }
        }

        Ok(self.tokens.clone())
    }

    pub fn next_token(&mut self) -> Result<Option<Token>, ErrorLexer> {
        let Some(&tok) = self.file.get(self.next) else {
            return Err(ErrorLexer::EOF);
        };

        match tok {
            '<' | '>' | '=' | '!' | '+' | '-' | '*' | '/' => {
                let &next_tok = self.file.get(self.next + 1).unwrap();

                match next_tok {
                    '=' => {
                        let double_tok = match tok {
                            '<' => Token::LessEqual,
                            '>' => Token::GreaterEqual,
                            '!' => Token::NotEqual,
                            '+' => Token::AddAssign,
                            '-' => Token::SubAssign,
                            '*' => Token::MulAssign,
                            '/' => Token::DivAssign,
                            _ => return Err(ErrorLexer::GenericSyntaxError),
                        };

                        self.next += 2;
                        Ok(Some(double_tok))
                    }

                    _ => {
                        let res = match tok {
                            '<' => Token::Less,
                            '>' => Token::Greater,
                            '!' => Token::Inverse,
                            '=' => Token::Assign,
                            '+' => Token::Add,
                            '-' => Token::Sub,
                            '*' => Token::Mul,
                            '/' => Token::Div,
                            _ => unreachable!(),
                        };

                        self.next += 1;
                        Ok(Some(res))
                    }
                }
            }

            '{' => {
                self.next += 1;
                Ok(Some(Token::LeftBrace))
            }

            '}' => {
                self.next += 1;
                Ok(Some(Token::RightBrace))
            }

            '"' => {
                let mut buf = String::new();
                let mut cnt = 1;
                while let Some(&c) = self.file.get(self.next + cnt) {
                    if c == '"' {
                        break;
                    }

                    buf.push(c);
                    cnt += 1;
                }

                self.next += cnt + 1;
                Ok(Some(Token::String(buf)))
            }

            x if x.is_ascii_digit() || x == '-' => {
                let mut buf = String::new();
                buf.push(x);
                let mut cnt = 1;
                while let Some(&c) = self.file.get(self.next + cnt) {
                    if c.is_ascii_whitespace() {
                        break;
                    }

                    buf.push(c);
                    cnt += 1;
                }

                println!("num: {buf}");

                self.next += cnt + 1;

                if buf.contains('.') {
                    Ok(Some(Token::Double(buf.parse::<f64>().unwrap().to_bits())))
                } else {
                    Ok(Some(Token::Integer(buf.parse::<i64>().unwrap() as u64)))
                }
            }

            '\n' => {
                self.next += 1;
                Ok(Some(Token::NewLine))
            }

            x if x.is_ascii_whitespace() => {
                self.next += 1;
                Ok(None)
            }

            // Multi-character tokens
            x => {
                let mut buf = String::new();
                buf.push(x);
                let mut cnt = 1;
                while let Some(&c) = self.file.get(self.next + cnt) {
                    if c.is_ascii_whitespace() {
                        break;
                    }

                    buf.push(c);
                    cnt += 1;
                }

                self.next += cnt;

                // NOTE: Match keywords
                match buf.as_str() {
                    "let" => {
                        let Some(&c) = self.file.get(self.next) else {
                            return Err(ErrorLexer::GenericSyntaxError);
                        };

                        if c != ' ' {
                            println!("{c}");
                            return Err(ErrorLexer::GenericSyntaxError);
                        }

                        let mut var_name = String::new();
                        let mut cnt = 1;
                        while let Some(&c) = self.file.get(self.next + cnt) {
                            if c.is_ascii_whitespace() {
                                break;
                            }

                            var_name.push(c);
                            cnt += 1;
                        }

                        self.next += cnt;
                        Ok(Some(Token::Variable(var_name)))
                    }

                    "fn" => {
                        let Some(&c) = self.file.get(self.next) else {
                            return Err(ErrorLexer::SyntaxError(SyntaxError::FunctionDefinition));
                        };

                        if c != ' ' {
                            println!("{c}");
                            return Err(ErrorLexer::SyntaxError(SyntaxError::FunctionDefinition));
                        }

                        let mut fn_name = String::new();
                        let mut cnt = 1;
                        while let Some(&c) = self.file.get(self.next + cnt) {
                            if c.is_ascii_whitespace() || c == '(' {
                                break;
                            }

                            fn_name.push(c);
                            cnt += 1;
                        }

                        let mut arguments = Vec::new();
                        while let Some(&c) = self.file.get(self.next + cnt) {}

                        self.next += cnt;
                        Ok(Some(Token::Function(fn_name)))
                    }

                    _ => Ok(Some(Token::Ident(buf))),
                }
            }
        }
    }
}
